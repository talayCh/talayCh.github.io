---
title: "Contrasting Discrete and Continuous Time Methodsfor Bayesian System Identification"
collection: publications
permalink: /publication/CTMML2022
excerpt: ''
date: 2022-07-23
authors:
  - 'SELF'
  - 'Carl Edward Rasmussen'
venue: 'Workshop on Continuous Time Methods in Machine Learning (CTMML) at the 39th International Conference on Machine Learning (ICML)'
paperurl: 'http://talayCh.github.io/files/2022_ctmml/paper.pdf'
slidesurl: 'http://talayCh.github.io/files/2022_ctmml/slides.pdf'
posterurl: 'http://talayCh.github.io/files/2022_ctmml/poster.pdf'
rawciteurl: 'http://talayCh.github.io/files/2022_ctmml/citation.txt'
---

In recent years, there has been considerable interest in embedding continuous time methods in machine learning algorithms. In system identification, the task is to learn a dynamical model from incomplete observation data, and when prior knowledge is in continuous time – for example, mechanistic differential equation models – it seems natural to use continuous time models for learning. Yet when learning flexible, nonlinear, probabilistic dynamics models, most previous work has focused on discrete time models to avoid computational, numerical, and mathematical difficulties. In this work we show, with the aid of small-scale examples, that this mismatch between model and data generating process can be consequential under certain circumstances, and we discuss possible modifications to discrete time models which may better suit them to handling data generated by continuous time processes.
