---
title: "Understanding Local Linearisation in Variational Gaussian Process State Space Models"
collection: publications
permalink: /publication/TSW2021
excerpt: ''
date: 2021-07-24
authors:
  - 'SELF'
venue: 'Time Series Workshop (TSW) at the 38th International Conference on Machine Learning (ICML)'
paperurl: 'http://talayCh.github.io/files/2021_tsw/paper.pdf'
posterurl: 'http://talayCh.github.io/files/2021_tsw/poster.pdf'
rawciteurl: 'http://talayCh.github.io/files/2021_tsw/citation.txt'
citation: 'Talay M Cheema. Understanding Local Linearisation in Variational Gaussian Process State Space Models. Time Series Workshop at the 28th International Conference on Machine Learning (ICML), 2021.'

---

We describe variational inference approaches in Gaussian process state space models in terms of local linearisations of the approximate posterior function. Most previous approaches have either assumed independence between the posterior dynamics and latent states (the mean-field (MF) approximation), or optimised free parameters for both, leading to limited scalability. We use our framework to prove that (i) there is a theoretical imperative to use non-MF approaches, to avoid excessive bias in the process noise hyperparameter estimate, and (ii) we can parameterise only the posterior dynamics without any less of performance. Our approach suggests further approximations, based on the existing rich literature on filtering and smoothing for nonlinear systems, and unifies approaches for discrete and continuous time models.
